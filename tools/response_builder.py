"""
Response Builder
Builds formatted response.md files.
"""

from typing import Dict, Any, Optional, List
from datetime import datetime


class ResponseBuilder:
    """Builds formatted response markdown."""

    def build_response(
        self,
        task: Dict[str, Any],
        usage: Dict[str, int],
        file_operations: List[Dict[str, Any]] = None,
        git_status: Optional[Dict[str, Any]] = None,
        claude_response: Optional[str] = None,
        context_size: int = 0
    ) -> str:
        """
        Build formatted response markdown.

        Args:
            task: Task dictionary from parser
            usage: Token usage dictionary
            file_operations: List of file operations performed
            git_status: Git status dictionary
            claude_response: Claude's response text (if no file operations)
            context_size: Size of context sent to Claude

        Returns:
            Formatted markdown string
        """
        response = []

        # Header
        response.append("# Task Response\n\n")
        response.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        # Task summary
        response.append("## 📋 Task Summary\n\n")
        response.append(f"**Project:** {task['project']}\n\n")
        response.append(f"**Task:** {task['task']}\n\n")
        response.append(f"**Priority:** {task['priority']}\n\n")

        # Claude's analysis (if no file operations)
        if claude_response:
            response.append("## 💬 Claude's Analysis\n\n")
            response.append(claude_response + "\n\n")

        # File operations
        if file_operations:
            response.append("## 📁 File Operations\n\n")

            for op in file_operations:
                op_type = op['operation']['type'].upper()
                op_path = op['operation']['path']
                success = op['success']

                status = "✅" if success else "❌"
                response.append(f"- {status} **{op_type}**: `{op_path}`\n")

                if not success and 'error' in op:
                    response.append(f"  - Error: {op['error']}\n")

            response.append("\n")

        # Git status
        if git_status:
            response.append("## 🔧 Git Status\n\n")
            response.append(f"**Branch:** {git_status['branch']}\n\n")
            response.append(f"**Status:** {git_status['changes']}\n\n")

        # Token usage and cost
        response.append("## 📊 Token Usage\n\n")
        response.append(f"- **Input tokens:** {usage['input_tokens']:,}\n")
        response.append(f"- **Output tokens:** {usage['output_tokens']:,}\n")
        response.append(f"- **Total tokens:** {usage['total_tokens']:,}\n")

        if context_size > 0:
            response.append(f"- **Context size:** ~{context_size:,} chars\n")

        # Calculate cost (Claude Sonnet 4.5 pricing)
        # Input: $3 per million tokens
        # Output: $15 per million tokens
        input_cost = (usage['input_tokens'] / 1_000_000) * 3
        output_cost = (usage['output_tokens'] / 1_000_000) * 15
        total_cost = input_cost + output_cost

        response.append(f"\n**Cost:** ${total_cost:.4f}\n")

        # Financial balance (placeholder - user should track this)
        response.append(f"\n💰 **Financial Balance:** (Track manually in your Anthropic dashboard)\n")
        response.append(f"   - This task cost: ${total_cost:.4f}\n")
        response.append(f"   - Check balance at: https://console.anthropic.com/settings/billing\n\n")

        # Footer
        response.append("---\n\n")
        response.append("*Generated by Claude Dev Automation*\n")

        return "".join(response)


# Test section
if __name__ == "__main__":
    print("\n[TEST] Testing ResponseBuilder...")

    try:
        builder = ResponseBuilder()

        # Test data
        test_task = {
            'project': 'test-project',
            'task': 'Test task description',
            'priority': 'NORMAL'
        }

        test_usage = {
            'input_tokens': 1500,
            'output_tokens': 500,
            'total_tokens': 2000
        }

        test_response = "This is Claude's analysis of the task."

        # Build response
        response_md = builder.build_response(
            task=test_task,
            usage=test_usage,
            claude_response=test_response,
            context_size=3000
        )

        print(f"\n[OK] Response built successfully:")
        print(f"     Length: {len(response_md)} chars")
        print(f"\n[INFO] Response preview:")
        print("-" * 60)
        print(response_md)
        print("-" * 60)

        print("\n[SUCCESS] ResponseBuilder test completed!")

    except Exception as e:
        print(f"\n[ERROR] Test failed: {e}")
        import traceback
        traceback.print_exc()